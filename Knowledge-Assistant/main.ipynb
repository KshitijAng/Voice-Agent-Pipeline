{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "405aebf7-1527-4bd7-96cd-706e98fe34e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks AI Agent — Knowledge Assistant\n",
    "An intelligent AI Agent powered by Databricks Llama-4 models that combines text reasoning and vision understanding to deliver context-rich results from multiple sources.\n",
    "\n",
    "\n",
    "⚙️ Tech Stack\n",
    "* Databricks Llama-4 Maverick (text reasoning)\n",
    "* LangChain (agent orchestration)\n",
    "* DuckDuckGo Search API\n",
    "* Wikipedia API\n",
    "\n",
    "\uD83D\uDCA1 Key Features\n",
    "* Zero-shot reasoning and planning with tool invocation\n",
    "* Seamless integration of textual + visual information\n",
    "* Structured, human-readable responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5118bd33-a4a7-4840-951d-70bbaca52b14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain ddgs langchain-community langchain-openai databricks-langchain wikipedia duckduckgo-search youtube_search langchain-databricks\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c19e3b22-cf02-4e44-ba4d-507d3e20a38d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tool Use / Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "00139129-c2f0-4683-9cef-6ec106e7978c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Wikipedia"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Page: Generative artificial intelligence\\nSummary: Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, audio, software code or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.\\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora. Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, Mistral AI, DeepSeek, Baidu and Yandex.\\nGenerative AI is used across many industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling. \\nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\\n\\nPage: Generative engine optimization\\nSummary: Generative engine optimization (GEO) is the practice of adapting digital content and online presence management to improve visibility in results produced by generative artificial intelligence (GenAI). The term was first introduced in November 2023 by six researchers in an academic paper. GEO describes strategies intended to influence the way large language models, such as ChatGPT, Google Gemini, Claude, and Perplexity, retrieve, summarize, and present information in response to user queries.\\nGEO exists within a broader ecosystem of content optimization strategies. While traditional Search Engine Optimization (SEO) focuses on improving rankings in conventional search engines, and Answer Engine Optimization (AEO) targets platforms that provide direct answers through voice assistants and featured snippets, GEO specifically addresses optimization for generative AI platforms that synthesize responses using large language models. Recent data indicate that approximately 53% of website traffic continues to originate from traditional organic search, yet an estimated 58% of queries are now conversational in nature, demonstrating the growing importance of GEO and AEO alongside traditional SEO methods. Industry practitioners increasingly recognize that SEO, AEO, and GEO represent complementary aspects of a unified content strategy rather than competing approaches.\\nUnlike traditional search engine optimization (SEO), which focuses on improving rankings in conventional search engines such as Google or Bing, GEO specifically targets generative engines — AI-driven systems that produce direct, summarized answers rather than lists of external links. The approach aims to ensure that brands and publishers are cited or represented on such platforms. Other terms used to describe the same concept include AI SEO (artificial intelligence search engine optimization) and LLMO (large language model optimization).\\n\\n\\n\\nPage: Generative pre-trained transformer\\nSummary: A generative pre-trained transformer (G'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "wikidata = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "wikidata.run(\"What is Generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fa780040-2feb-4e49-878d-dc688a40900d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DuckDuckGo"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search.run(\"What is Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "39193f0b-d25b-4765-aace-d4b982f4b255",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Youtube"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "yt_tool = YouTubeSearchTool()\n",
    "yt_tool.run(\"The Data master\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a9c1f3a-038a-4e22-b646-69f6091a3fc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5737ec-3e53-40e0-8a6e-4f8eda150007",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "from langchain.agents import Tool,initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f20edb8f-928f-4f45-8764-f0339b101015",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-4c235d2f-cabe-4a55-9d35-ec/.ipykernel/8269/command-8300480422093416-3474296969:29: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n  agent = initialize_agent(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDC4B Hello! What topic are you exploring today?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter a topic:  Neural Networks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n\u001B[32;1m\u001B[1;3mTo summarize Neural Networks and list 2 YouTube videos related to the topic, I need to first gather information from Wikipedia about Neural Networks. Then, I will search YouTube for relevant videos.\n\nAction: Wikipedia\nAction Input: {'query': 'Neural Networks'}\u001B[0m\nObservation: \u001B[36;1m\u001B[1;3mPage: Transformer (deep learning architecture)\nSummary: In deep learning, the transformer is a neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\n\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\n\n\n\nPage: Convolutional neural network\nSummary: A convolutional neural network (CNN) is a type of feedforward neural network that learns features via filter (or kernel) optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text, images and audio. Convolution-based networks are the de-facto standard in deep learning-based approaches to computer vision and image processing, and have only recently been replaced—in some cases—by newer deep learning architectures such as the transformer.\nVanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by the regularization that comes from using shared weights over fewer connections. For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 × 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels, only 25 weights for each convolutional layer are required to process 5x5-sized tiles. Higher-layer features are extracted from wider context windows, compared to lower-layer features.\nSome applications of CNNs include: \n\nimage and video recognition,\nrecommender systems,\nimage classification,\nimage segmentation,\nmedical image analysis,\nnatural language processing,\nbrain–computer interfaces, and\nfinancial time series.\nCNNs are also known as shift invariant or space invariant artificial neural networks, based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are not invariant to translation, due to the downsampling operation they apply to the input.\nFeedforward neural networks are usually fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"full connectivity\" of these networks makes them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly-populated set.\nConvolutional networks were inspired by biological proce\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mThe Wikipedia page returned information related to Neural Networks, but it provided summaries of specific types of neural networks, such as Transformer and Convolutional Neural Network (CNN), rather than a general summary of Neural Networks. I need to refine my search to get a more general overview of Neural Networks.\n\nAction: Wikipedia\nAction Input: {'query': 'Artificial Neural Network'}\u001B[0m\nObservation: \u001B[36;1m\u001B[1;3mPage: Types of artificial neural networks\nSummary: There are many types of artificial neural networks (ANN).\nArtificial neural networks are computational models inspired by biological neural networks, and are used to approximate functions that are generally unknown. Particularly, they are inspired by the behaviour of neurons and the electrical signals they convey between input (such as from the eyes or nerve endings in the hand), processing, and output from the brain (such as reacting to light, touch, or heat). The way neurons semantically communicate is an area of ongoing research. Most artificial neural networks bear only some resemblance to their more complex biological counterparts, but are very effective at their intended tasks (e.g. classification or segmentation).\nSome artificial neural networks are adaptive systems and are used for example to model populations and environments, which constantly change.\nNeural networks can be hardware- (neurons are represented by physical components) or software-based (computer models), and can use a variety of topologies and learning algorithms.\n\nPage: Attention Is All You Need\nSummary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, and a main contributor to the AI boom, as the transformer approach has become the main architecture of a wide variety of AI, such as large language models. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique's potential for other tasks like question answering and what is now known as multimodal generative AI.\nThe paper's title is a reference to the song \"All You Need Is Love\" by the Beatles. The name \"Transformer\" was picked because Jakob Uszkoreit, one of the paper's authors, liked the sound of that word.\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for Various Tasks\", and included an illustration of six characters from the Transformers franchise. The team was named Team Transformer.\nSome early examples that the team tried their Transformer architecture on included English-to-German translation, generating Wikipedia articles on \"The Transformer\", and parsing. These convinced the team that the Transformer is a general purpose language model, and not just good for translation.\nAs of 2025, the paper has been cited more than 173,000 times, placing it among the top ten most-cited papers of the 21st century.\n\nPage: Transformer (deep learning architecture)\nSummary: In deep learning, the transformer is a neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\n\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language proce\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mThought: The Wikipedia search results still don't provide a direct summary of Neural Networks. I need to refine my search to get a general overview of Neural Networks.\n\nAction: Wikipedia\nAction Input: {'query': 'Neural Network'}\u001B[0m\nObservation: \u001B[36;1m\u001B[1;3mPage: Transformer (deep learning architecture)\nSummary: In deep learning, the transformer is a neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\n\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\n\n\n\nPage: Convolutional neural network\nSummary: A convolutional neural network (CNN) is a type of feedforward neural network that learns features via filter (or kernel) optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text, images and audio. Convolution-based networks are the de-facto standard in deep learning-based approaches to computer vision and image processing, and have only recently been replaced—in some cases—by newer deep learning architectures such as the transformer.\nVanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by the regularization that comes from using shared weights over fewer connections. For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 × 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels, only 25 weights for each convolutional layer are required to process 5x5-sized tiles. Higher-layer features are extracted from wider context windows, compared to lower-layer features.\nSome applications of CNNs include: \n\nimage and video recognition,\nrecommender systems,\nimage classification,\nimage segmentation,\nmedical image analysis,\nnatural language processing,\nbrain–computer interfaces, and\nfinancial time series.\nCNNs are also known as shift invariant or space invariant artificial neural networks, based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are not invariant to translation, due to the downsampling operation they apply to the input.\nFeedforward neural networks are usually fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"full connectivity\" of these networks makes them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly-populated set.\nConvolutional networks were inspired by biological proce\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mThought: The Wikipedia search results still don't provide a direct summary of Neural Networks. I need to refine my search to get a general overview of Neural Networks. Let me try searching for \"Artificial Neural Network\" again.\n\nAction: Wikipedia\nAction Input: {'query': 'Artificial Neural Network'}\u001B[0m\nObservation: \u001B[36;1m\u001B[1;3mPage: Types of artificial neural networks\nSummary: There are many types of artificial neural networks (ANN).\nArtificial neural networks are computational models inspired by biological neural networks, and are used to approximate functions that are generally unknown. Particularly, they are inspired by the behaviour of neurons and the electrical signals they convey between input (such as from the eyes or nerve endings in the hand), processing, and output from the brain (such as reacting to light, touch, or heat). The way neurons semantically communicate is an area of ongoing research. Most artificial neural networks bear only some resemblance to their more complex biological counterparts, but are very effective at their intended tasks (e.g. classification or segmentation).\nSome artificial neural networks are adaptive systems and are used for example to model populations and environments, which constantly change.\nNeural networks can be hardware- (neurons are represented by physical components) or software-based (computer models), and can use a variety of topologies and learning algorithms.\n\nPage: Attention Is All You Need\nSummary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, and a main contributor to the AI boom, as the transformer approach has become the main architecture of a wide variety of AI, such as large language models. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique's potential for other tasks like question answering and what is now known as multimodal generative AI.\nThe paper's title is a reference to the song \"All You Need Is Love\" by the Beatles. The name \"Transformer\" was picked because Jakob Uszkoreit, one of the paper's authors, liked the sound of that word.\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for Various Tasks\", and included an illustration of six characters from the Transformers franchise. The team was named Team Transformer.\nSome early examples that the team tried their Transformer architecture on included English-to-German translation, generating Wikipedia articles on \"The Transformer\", and parsing. These convinced the team that the Transformer is a general purpose language model, and not just good for translation.\nAs of 2025, the paper has been cited more than 173,000 times, placing it among the top ten most-cited papers of the 21st century.\n\nPage: Transformer (deep learning architecture)\nSummary: In deep learning, the transformer is a neural network architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. \nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\n\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. The predecessors of transformers were developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language proce\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mThought: The Wikipedia page titled \"Types of artificial neural networks\" provides a general overview of Artificial Neural Networks (ANNs). I will use this information to summarize Neural Networks. Then, I will search YouTube for relevant videos.\n\nAction: YouTube\nAction Input: {'query': 'Neural Networks explained'}\u001B[0m\nObservation: \u001B[33;1m\u001B[1;3m['https://www.youtube.com/watch?v=jmmW0F0biz0&pp=ygUmeydxdWVyeSc6ICdOZXVyYWwgTmV0d29ya3MgZXhwbGFpbmVkJ30%3D', 'https://www.youtube.com/watch?v=aircAruvnKk&pp=ygUmeydxdWVyeSc6ICdOZXVyYWwgTmV0d29ya3MgZXhwbGFpbmVkJ30%3D']\u001B[0m\nThought:\u001B[32;1m\u001B[1;3mThought: I have gathered a general overview of Artificial Neural Networks from Wikipedia and found two YouTube videos that explain Neural Networks. Now, I will summarize the information and list the YouTube videos.\n\nFinal Answer: \nArtificial Neural Networks (ANNs) are computational models inspired by biological neural networks. They are used to approximate unknown functions and are effective in tasks such as classification and segmentation. ANNs can be hardware- or software-based and use various topologies and learning algorithms. They are adaptive systems that can model changing populations and environments.\n\nTwo YouTube videos that explain Neural Networks are:\n1. https://www.youtube.com/watch?v=jmmW0F0biz0\n2. https://www.youtube.com/watch?v=aircAruvnKk\u001B[0m\n\n\u001B[1m> Finished chain.\u001B[0m\n\n\uD83D\uDCD8 Here's what I found:\n\nArtificial Neural Networks (ANNs) are computational models inspired by biological neural networks. They are used to approximate unknown functions and are effective in tasks such as classification and segmentation. ANNs can be hardware- or software-based and use various topologies and learning algorithms. They are adaptive systems that can model changing populations and environments.\n\nTwo YouTube videos that explain Neural Networks are:\n1. https://www.youtube.com/watch?v=jmmW0F0biz0\n2. https://www.youtube.com/watch?v=aircAruvnKk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Initialize Model from Databricks Serving Endpoint ----\n",
    "chat_model = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\")\n",
    "\n",
    "# ---- Wikipedia Tool ----\n",
    "wiki_tool = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func= WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()).run,\n",
    "    description=(\n",
    "        \"Search Wikipedia for accurate and concise educational information \"\n",
    "        \"on topics such as artificial intelligence, cloud computing, data engineering, \"\n",
    "        \"and software development.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ---- Youtube Tool ----\n",
    "youtube_tool = Tool(\n",
    "    name=\"YouTube\",\n",
    "    func= YouTubeSearchTool().run,\n",
    "    description=(\n",
    "        \"Search YouTube for video tutorials, tech talks, or educational resources \"\n",
    "        \"related to AI, data, and cloud technologies.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ---- Combine Tools ----\n",
    "tools = [wiki_tool, youtube_tool]\n",
    "\n",
    "# ---- Initialize the AI Agent ----\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=chat_model,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ---- Interactive Prompt ----\n",
    "print(\"\uD83D\uDC4B Hello! What topic are you exploring today?\")\n",
    "theme = input(\"Enter a topic: \")\n",
    "\n",
    "try:\n",
    "    query = f\"Summarize {theme} from Wikipedia and list 2 YouTube videos.\"\n",
    "    if query:\n",
    "        response = agent.invoke({\"input\": query})\n",
    "        print(\"\\n\uD83D\uDCD8 Here's what I found:\\n\")\n",
    "        print(response[\"output\"])\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AI Agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}